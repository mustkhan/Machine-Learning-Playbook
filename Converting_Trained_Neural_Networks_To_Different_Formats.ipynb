{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Converting Trained Neural Networks To Different Formats.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7++J8odNJ65JXYIMRxUL6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustafaKhan670093/Machine-Learning-Playbook/blob/master/Converting_Trained_Neural_Networks_To_Different_Formats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Converting Trained NNs To Different Formats**\n",
        "\n",
        "A lot of RND work is done using Pytorch. However, deploying models on edge devices usually requires a conversion to ONNX or to (Tensorflow and then) Tensorflow Lite. This notebook covers this conversion process."
      ],
      "metadata": {
        "id": "6pvh0UFYxyHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Install Dependencies**\n",
        "\n",
        "Run the following cell and then restart the runtime so that you can use these libraries."
      ],
      "metadata": {
        "id": "vNwr-7S6zA9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiOPdCkxxrDc"
      },
      "outputs": [],
      "source": [
        "!pip install torchvision\n",
        "!pip install onnx\n",
        "!pip install  onnx-tf==1.5.0\n",
        "!pip install tensorflow-addons\n",
        "!git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow && pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Let's Train A Simple MNIST Classifier**\n",
        "\n",
        "At the end of this section, a network that can classify MNIST digits has been trained and saved in a `model.pt` file."
      ],
      "metadata": {
        "id": "LmRcwt-ayqCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "FMyFKikc5-3f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_workers = 0\n",
        "batch_size = 20\n",
        "valid_size = 0.2\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
        "\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "oXLSvJuf56Ng"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "model = Net()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "fqq3lfxtypOm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50\n",
        "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in valid_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'mnist.pth')\n",
        "        valid_loss_min = valid_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gKulG1K6vm1",
        "outputId": "0eab198d-0adf-49a2-df25-43a279a77d44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.267271 \tValidation Loss: 0.342553\n",
            "Validation loss decreased (inf --> 0.342553).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.502955 \tValidation Loss: 0.207912\n",
            "Validation loss decreased (0.342553 --> 0.207912).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.387287 \tValidation Loss: 0.157670\n",
            "Validation loss decreased (0.207912 --> 0.157670).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.330789 \tValidation Loss: 0.132818\n",
            "Validation loss decreased (0.157670 --> 0.132818).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.297623 \tValidation Loss: 0.121562\n",
            "Validation loss decreased (0.132818 --> 0.121562).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.264539 \tValidation Loss: 0.104081\n",
            "Validation loss decreased (0.121562 --> 0.104081).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 0.252966 \tValidation Loss: 0.099216\n",
            "Validation loss decreased (0.104081 --> 0.099216).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.236357 \tValidation Loss: 0.101093\n",
            "Epoch: 9 \tTraining Loss: 0.218656 \tValidation Loss: 0.088543\n",
            "Validation loss decreased (0.099216 --> 0.088543).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.213702 \tValidation Loss: 0.082569\n",
            "Validation loss decreased (0.088543 --> 0.082569).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.204031 \tValidation Loss: 0.080764\n",
            "Validation loss decreased (0.082569 --> 0.080764).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.197050 \tValidation Loss: 0.079651\n",
            "Validation loss decreased (0.080764 --> 0.079651).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.186745 \tValidation Loss: 0.075319\n",
            "Validation loss decreased (0.079651 --> 0.075319).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 0.184098 \tValidation Loss: 0.074684\n",
            "Validation loss decreased (0.075319 --> 0.074684).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 0.177446 \tValidation Loss: 0.070579\n",
            "Validation loss decreased (0.074684 --> 0.070579).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 0.167494 \tValidation Loss: 0.070872\n",
            "Epoch: 17 \tTraining Loss: 0.169970 \tValidation Loss: 0.069767\n",
            "Validation loss decreased (0.070579 --> 0.069767).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 0.162152 \tValidation Loss: 0.067658\n",
            "Validation loss decreased (0.069767 --> 0.067658).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 0.156383 \tValidation Loss: 0.064622\n",
            "Validation loss decreased (0.067658 --> 0.064622).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 0.153365 \tValidation Loss: 0.062501\n",
            "Validation loss decreased (0.064622 --> 0.062501).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 0.152363 \tValidation Loss: 0.060886\n",
            "Validation loss decreased (0.062501 --> 0.060886).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 0.147660 \tValidation Loss: 0.060789\n",
            "Validation loss decreased (0.060886 --> 0.060789).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 0.146339 \tValidation Loss: 0.059402\n",
            "Validation loss decreased (0.060789 --> 0.059402).  Saving model ...\n",
            "Epoch: 24 \tTraining Loss: 0.141456 \tValidation Loss: 0.063125\n",
            "Epoch: 25 \tTraining Loss: 0.139716 \tValidation Loss: 0.059856\n",
            "Epoch: 26 \tTraining Loss: 0.137582 \tValidation Loss: 0.060112\n",
            "Epoch: 27 \tTraining Loss: 0.136065 \tValidation Loss: 0.056440\n",
            "Validation loss decreased (0.059402 --> 0.056440).  Saving model ...\n",
            "Epoch: 28 \tTraining Loss: 0.139611 \tValidation Loss: 0.056917\n",
            "Epoch: 29 \tTraining Loss: 0.127848 \tValidation Loss: 0.058351\n",
            "Epoch: 30 \tTraining Loss: 0.131546 \tValidation Loss: 0.053586\n",
            "Validation loss decreased (0.056440 --> 0.053586).  Saving model ...\n",
            "Epoch: 31 \tTraining Loss: 0.123094 \tValidation Loss: 0.056453\n",
            "Epoch: 32 \tTraining Loss: 0.126216 \tValidation Loss: 0.053788\n",
            "Epoch: 33 \tTraining Loss: 0.128485 \tValidation Loss: 0.052678\n",
            "Validation loss decreased (0.053586 --> 0.052678).  Saving model ...\n",
            "Epoch: 34 \tTraining Loss: 0.126749 \tValidation Loss: 0.055208\n",
            "Epoch: 35 \tTraining Loss: 0.123160 \tValidation Loss: 0.052527\n",
            "Validation loss decreased (0.052678 --> 0.052527).  Saving model ...\n",
            "Epoch: 36 \tTraining Loss: 0.121753 \tValidation Loss: 0.051915\n",
            "Validation loss decreased (0.052527 --> 0.051915).  Saving model ...\n",
            "Epoch: 37 \tTraining Loss: 0.118582 \tValidation Loss: 0.051953\n",
            "Epoch: 38 \tTraining Loss: 0.122159 \tValidation Loss: 0.053472\n",
            "Epoch: 39 \tTraining Loss: 0.116040 \tValidation Loss: 0.050120\n",
            "Validation loss decreased (0.051915 --> 0.050120).  Saving model ...\n",
            "Epoch: 40 \tTraining Loss: 0.115647 \tValidation Loss: 0.052118\n",
            "Epoch: 41 \tTraining Loss: 0.117931 \tValidation Loss: 0.050662\n",
            "Epoch: 42 \tTraining Loss: 0.113400 \tValidation Loss: 0.050739\n",
            "Epoch: 43 \tTraining Loss: 0.114481 \tValidation Loss: 0.050495\n",
            "Epoch: 44 \tTraining Loss: 0.110681 \tValidation Loss: 0.049443\n",
            "Validation loss decreased (0.050120 --> 0.049443).  Saving model ...\n",
            "Epoch: 45 \tTraining Loss: 0.107701 \tValidation Loss: 0.049740\n",
            "Epoch: 46 \tTraining Loss: 0.109410 \tValidation Loss: 0.048364\n",
            "Validation loss decreased (0.049443 --> 0.048364).  Saving model ...\n",
            "Epoch: 47 \tTraining Loss: 0.107995 \tValidation Loss: 0.050642\n",
            "Epoch: 48 \tTraining Loss: 0.107996 \tValidation Loss: 0.050093\n",
            "Epoch: 49 \tTraining Loss: 0.109810 \tValidation Loss: 0.048294\n",
            "Validation loss decreased (0.048364 --> 0.048294).  Saving model ...\n",
            "Epoch: 50 \tTraining Loss: 0.104885 \tValidation Loss: 0.046887\n",
            "Validation loss decreased (0.048294 --> 0.046887).  Saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load The Saved Pytorch Model And Export It As An ONNX File**"
      ],
      "metadata": {
        "id": "TiMrE7L84Tzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import onnx\n",
        "from onnx_tf.backend import prepare\n",
        "\n",
        "#Load Saved Pytorch Model\n",
        "trained_model = Net()\n",
        "trained_model.load_state_dict(torch.load('mnist.pth'))\n",
        "\n",
        "#Export to ONNX\n",
        "dummy_input = Variable(torch.randn(1, 1, 28, 28)) \n",
        "torch.onnx.export(trained_model, dummy_input, \"mnist.onnx\")"
      ],
      "metadata": {
        "id": "HafpYhaZ4VCc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load The ONNX File And Import It With Tensorflow**"
      ],
      "metadata": {
        "id": "PApS-UX75MO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load ONNX file\n",
        "model = onnx.load('mnist.onnx')\n",
        "\n",
        "#Import ONNX model with Tensorflow\n",
        "tf_model = prepare(model)"
      ],
      "metadata": {
        "id": "jI6wKRtx5MyU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test The Tensorflow Model To Check It Works**"
      ],
      "metadata": {
        "id": "aPRurWsI948W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "print('Test Image')\n",
        "img = Image.open('/content/img1.png').resize((28, 28)).convert('L')\n",
        "display(img)\n",
        "output = tf_model.run(np.asarray(img, dtype=np.float32)[np.newaxis, np.newaxis, :, :])\n",
        "print('The digit is classified as a', np.argmax(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ZzOYXZ1CBs7o",
        "outputId": "85ea11db-f609-4ba1-e42c-694d69c2fc72"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJmVYSWZNTQAqAAAACAACQAAAAwAAAAEAEQAAQAEAAQAAAAEAAAAAAAAAACHbNZQAAAG9SURBVHicZZKxa1NRFMZ/5+W1jVZFTB/WDAqpoq1txZBF0XYyq4Pin+AkCC4KUnAqloJDiw6OddChoDi5CDpa4mJSihgH0YYmoFJJagLhHId738sDv+lwvu/c75xzjygAyP0VOX2uODNxNAOAAYgjZavYBQhzJ85MT5/MjwJY6Ap50RWAfrO5AfuPnTo7O1nIoaqq1plEBgAgyN/x5BshTg8UQ/7ZZ+bkUdhUAAGxG6KANGZ+CYC8nKtvVWv17T1A3rnKV46zaDwolWBvu75Z2716CVW1/kXvFGTz8/fedswDVbWNIdJ9Tj1smamqoqp2G+eYCArPzWJyKQO+KuYXTFXd+irfDx/gb/PLxw8N94ixestAVdUStJ5Efhu5b6aoOnMHs/eHPPvYNEB6Pe8HmM1d9uEmBLJ6vvjgZ0ILv300DHweBSYe/Yhd10Lf8JopC4gIjF1/Wtlp7366u89bRg1TxpO/yowVjo8kky6aKuXU5KnwWtdU6a2Xs6ndedXNtqkqZlZdvhKRQjj/2s0uigA7tUr1a+tPX4aPFC6US0H6NN0+O+0+Iwez8dUmd5soEgIgHISprEfwXyaFf93B5OO9oVi9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F810F665C50>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The digit is classified as a 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save The Tensorflow Model**"
      ],
      "metadata": {
        "id": "qNvKe0uMEXYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_model.export_graph('mnist.pb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAXCv7agEaI_",
        "outputId": "3102a0b0-855b-4c0b-8ce4-2620422a5a6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `__call__` contains input name(s) input.1 with unsupported characters which will be renamed to input_1 in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: mnist.pb/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: mnist.pb/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#Helper functions to calculate model file sizes\n",
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size\n",
        "\n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
        "    elif unit == \"MB\":\n",
        "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
        "    else:\n",
        "        return print('File size: ' + str(size) + ' bytes')\n",
        "\n",
        "TENSORFLOW_MODEL_NAME = '/content/mnist.pb/saved_model.pb'      \n",
        "convert_bytes(get_file_size(TENSORFLOW_MODEL_NAME), \"KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8NyirLrE-xp",
        "outputId": "817d2abc-6480-45d3-918f-15fffeeada7b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 112.769 Kilobytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Convert Tensorflow Model To Tensorflow Lite**"
      ],
      "metadata": {
        "id": "J0PPxieQEdkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Make a converter object from the saved tensorflow file\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('mnist.pb')\n",
        "\n",
        "#Tell converter which type of optimization techniques to use\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "#To view the best option for optimization read documentation of tflite about optimization\n",
        "# go to this link https://www.tensorflow.org/lite/guide/get_started#4_optimize_your_model_optional\n",
        "\n",
        "#Convert the model \n",
        "tf_lite_model = converter.convert()\n",
        "\n",
        "#Save the converted model \n",
        "open('mnist.tflite', 'wb').write(tf_lite_model)\n",
        "\n",
        "TF_LITE_MODEL_FILE_NAME = 'mnist.tflite'\n",
        "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5sgTS_tJW_B",
        "outputId": "b87dddbf-e3bf-45ea-a062-d5bfddaa3417"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 27.406 Kilobytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test If Tensorflow Lite Model Works**"
      ],
      "metadata": {
        "id": "sa0iLh8GK2Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# If you have a folder of images you want to test, change 1 to the number of images\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (28, 28))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (1, 10))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])\n",
        "\n",
        "#Loading image from earlier\n",
        "image = np.array(img, dtype=np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsSzQ98wK5LV",
        "outputId": "c3c1cf46-95ad-46d8-dcd5-f623ed167779"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: [28 28]\n",
            "Input Type: <class 'numpy.float32'>\n",
            "Output Shape: [ 1 10]\n",
            "Output Type: <class 'numpy.float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_imgs_numpy = np.array(image, dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
        "interpreter.invoke()\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)\n",
        "display(img)\n",
        "print(\"The digit is classified as a \" + str(prediction_classes[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "4bau5AlJLhBa",
        "outputId": "fd41a1a9-1a55-478d-fd61-31aaac59aa6b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction results shape: (1, 10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJmVYSWZNTQAqAAAACAACQAAAAwAAAAEAEQAAQAEAAQAAAAEAAAAAAAAAACHbNZQAAAG9SURBVHicZZKxa1NRFMZ/5+W1jVZFTB/WDAqpoq1txZBF0XYyq4Pin+AkCC4KUnAqloJDiw6OddChoDi5CDpa4mJSihgH0YYmoFJJagLhHId738sDv+lwvu/c75xzjygAyP0VOX2uODNxNAOAAYgjZavYBQhzJ85MT5/MjwJY6Ap50RWAfrO5AfuPnTo7O1nIoaqq1plEBgAgyN/x5BshTg8UQ/7ZZ+bkUdhUAAGxG6KANGZ+CYC8nKtvVWv17T1A3rnKV46zaDwolWBvu75Z2716CVW1/kXvFGTz8/fedswDVbWNIdJ9Tj1smamqoqp2G+eYCArPzWJyKQO+KuYXTFXd+irfDx/gb/PLxw8N94ixestAVdUStJ5Efhu5b6aoOnMHs/eHPPvYNEB6Pe8HmM1d9uEmBLJ6vvjgZ0ILv300DHweBSYe/Yhd10Lf8JopC4gIjF1/Wtlp7366u89bRg1TxpO/yowVjo8kky6aKuXU5KnwWtdU6a2Xs6ndedXNtqkqZlZdvhKRQjj/2s0uigA7tUr1a+tPX4aPFC6US0H6NN0+O+0+Iwez8dUmd5soEgIgHISprEfwXyaFf93B5OO9oVi9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F810F665C50>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The digit is classified as a 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensorflow Lite is able to be run on devices such as a phone or a Raspberry Pi (with a Coral USB Accelerator)."
      ],
      "metadata": {
        "id": "9PhnxtnrQ-88"
      }
    }
  ]
}